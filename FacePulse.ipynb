{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ACFQ9-JOJv3A"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5uAXLTkKAFo",
        "outputId": "e1f9c674-f0a6-4993-ff21-d141667e6d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-09-21 15:44:58--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 930127 (908K) [text/plain]\n",
            "Saving to: ‘haarcascade_frontalface_default.xml.1’\n",
            "\n",
            "\r          haarcasca   0%[                    ]       0  --.-KB/s               \rhaarcascade_frontal 100%[===================>] 908.33K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-09-21 15:44:59 (15.1 MB/s) - ‘haarcascade_frontalface_default.xml.1’ saved [930127/930127]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download haarcascade_frontalface_default.xml\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wnzx1oQvLikO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'YOUR_NGROK_AUTHTOKEN' with the actual authtoken you obtained\n",
        "ngrok.set_auth_token(\"YOUR_NGROK_AUTHTOKEN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L8TGwU2KG5V",
        "outputId": "5569c7fb-a9c9-43f5-a9cf-c677950c2f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Function to ensure directories exist\n",
        "def assure_path_exists(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "# Function to get images and labels for training\n",
        "def getImagesAndLabels(path):\n",
        "    imagePaths = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.jpg')]\n",
        "    faces = []\n",
        "    Ids = []\n",
        "    for imagePath in imagePaths:\n",
        "        pilImage = Image.open(imagePath).convert('L')  # grayscale\n",
        "        imageNp = np.array(pilImage, 'uint8')\n",
        "        # Assuming the image filename format: name.ID.sampleNum.jpg\n",
        "        try:\n",
        "            ID = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
        "            faces.append(imageNp)\n",
        "            Ids.append(ID)\n",
        "        except:\n",
        "            continue  # skip files that don't match the naming convention\n",
        "    return faces, Ids\n",
        "\n",
        "# Initialize session state for captured images\n",
        "if 'captured_images' not in st.session_state:\n",
        "    st.session_state.captured_images = []\n",
        "\n",
        "# Initialize session state for attendance records\n",
        "if 'attendance_records' not in st.session_state:\n",
        "    st.session_state.attendance_records = []\n",
        "\n",
        "st.title(\"FacePulse AI: Facial Attendance System\")\n",
        "\n",
        "menu = [\"Register\", \"Train\", \"Attendance\", \"About\"]\n",
        "choice = st.sidebar.selectbox(\"Menu\", menu)\n",
        "\n",
        "if choice == \"Register\":\n",
        "    st.subheader(\"Register New User\")\n",
        "    with st.form(\"register_form\"):\n",
        "        Id = st.text_input(\"Enter ID\")\n",
        "        name = st.text_input(\"Enter Name\")\n",
        "        submit = st.form_submit_button(\"Start Registration\")\n",
        "\n",
        "    if submit:\n",
        "        if not Id or not name:\n",
        "            st.error(\"Please enter both ID and Name.\")\n",
        "        elif not name.replace(' ', '').isalpha():\n",
        "            st.error(\"Name should contain only alphabets and spaces.\")\n",
        "        else:\n",
        "            st.success(f\"Registration started for {name} with ID {Id}.\")\n",
        "            st.write(\"Please capture images by clicking the 'Capture Image' button below.\")\n",
        "\n",
        "            # Capture Images\n",
        "            if st.button(\"Capture Image\"):\n",
        "                image = st.camera_input(\"Take a picture\")\n",
        "                if image:\n",
        "                    img = Image.open(image)\n",
        "                    img_np = np.array(img)\n",
        "                    st.image(img, caption='Captured Image', use_column_width=True)\n",
        "                    # Convert RGB to BGR for OpenCV\n",
        "                    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
        "                    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "                    faces = cv2.CascadeClassifier('haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
        "                    for (x, y, w, h) in faces:\n",
        "                        face_img = gray[y:y+h, x:x+w]\n",
        "                        st.session_state.captured_images.append(face_img)\n",
        "                        st.success(f\"Image {len(st.session_state.captured_images)} captured.\")\n",
        "                        break  # Capture one face per image\n",
        "\n",
        "            # Display number of captured images\n",
        "            st.write(f\"Total Images Captured: {len(st.session_state.captured_images)}\")\n",
        "            st.write(\"Capture at least 10 images for effective training.\")\n",
        "\n",
        "            # Save Images\n",
        "            if st.button(\"Save Images\") and len(st.session_state.captured_images) >= 10:\n",
        "                assure_path_exists(\"TrainingImage\")\n",
        "                serial = 0\n",
        "                # Check existing CSV to get the next serial number\n",
        "                if os.path.isfile(\"StudentDetails/StudentDetails.csv\"):\n",
        "                    df_existing = pd.read_csv(\"StudentDetails/StudentDetails.csv\")\n",
        "                    serial = len(df_existing) + 1\n",
        "                else:\n",
        "                    columns = ['SERIAL NO.', 'ID', 'NAME']\n",
        "                    df_existing = pd.DataFrame(columns=columns)\n",
        "                    serial = 1\n",
        "\n",
        "                # Save each captured image\n",
        "                for idx, face in enumerate(st.session_state.captured_images):\n",
        "                    img_path = f\"TrainingImage/{name}.{Id}.{serial}.{idx+1}.jpg\"\n",
        "                    cv2.imwrite(img_path, face)\n",
        "\n",
        "                # Save user details to CSV\n",
        "                new_entry = {'SERIAL NO.': serial, 'ID': Id, 'NAME': name}\n",
        "                df_existing = df_existing.append(new_entry, ignore_index=True)\n",
        "                df_existing.to_csv(\"StudentDetails/StudentDetails.csv\", index=False)\n",
        "\n",
        "                st.success(f\"Images and profile saved for {name} with ID {Id}.\")\n",
        "\n",
        "                # Clear captured images from session state\n",
        "                st.session_state.captured_images = []\n",
        "            elif st.button(\"Save Images\") and len(st.session_state.captured_images) < 10:\n",
        "                st.warning(\"Please capture at least 10 images before saving.\")\n",
        "\n",
        "elif choice == \"Train\":\n",
        "    st.subheader(\"Train the Model\")\n",
        "    if st.button(\"Train Images\"):\n",
        "        if not os.path.exists(\"TrainingImage\"):\n",
        "            st.error(\"No training images found. Please register users first.\")\n",
        "        else:\n",
        "            faces, Ids = getImagesAndLabels(\"TrainingImage\")\n",
        "            if len(faces) == 0:\n",
        "                st.error(\"No valid training images found.\")\n",
        "            else:\n",
        "                recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "                recognizer.train(faces, np.array(Ids))\n",
        "                recognizer.save(\"TrainingImageLabel/Trainer.yml\")\n",
        "                st.success(\"Model trained and saved successfully.\")\n",
        "\n",
        "elif choice == \"Attendance\":\n",
        "    st.subheader(\"Take Attendance\")\n",
        "    if st.button(\"Start Attendance\"):\n",
        "        if not os.path.isfile(\"TrainingImageLabel/Trainer.yml\"):\n",
        "            st.error(\"Model not found. Please train the model first.\")\n",
        "        elif not os.path.isfile(\"StudentDetails/StudentDetails.csv\"):\n",
        "            st.error(\"Student details not found. Please register users first.\")\n",
        "        else:\n",
        "            # Load the trained model\n",
        "            recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "            recognizer.read(\"TrainingImageLabel/Trainer.yml\")\n",
        "\n",
        "            # Load student details\n",
        "            df = pd.read_csv(\"StudentDetails/StudentDetails.csv\")\n",
        "\n",
        "            # Capture attendance via webcam\n",
        "            st.write(\"Starting webcam for attendance tracking...\")\n",
        "            cap = cv2.VideoCapture(0)\n",
        "            stframe = st.empty()\n",
        "            attendance = []\n",
        "\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    st.error(\"Failed to access the webcam.\")\n",
        "                    break\n",
        "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                faces = cv2.CascadeClassifier('haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "                for (x, y, w, h) in faces:\n",
        "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "                    serial, conf = recognizer.predict(gray[y:y+h, x:x+w])\n",
        "                    if conf < 50:\n",
        "                        name = df.loc[df['SERIAL NO.'] == serial]['NAME'].values\n",
        "                        ID = df.loc[df['SERIAL NO.'] == serial]['ID'].values\n",
        "                        name = name[0] if len(name) > 0 else \"Unknown\"\n",
        "                        ID = ID[0] if len(ID) > 0 else \"Unknown\"\n",
        "                        cv2.putText(frame, str(name), (x, y+h+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "                        # Mark attendance\n",
        "                        ts = datetime.datetime.now()\n",
        "                        date = ts.strftime('%d-%m-%Y')\n",
        "                        timeStamp = ts.strftime('%H:%M:%S')\n",
        "                        attendance_record = {'ID': ID, 'Name': name, 'Date': date, 'Time': timeStamp}\n",
        "                        if attendance_record not in attendance:\n",
        "                            attendance.append(attendance_record)\n",
        "                            # Save to CSV\n",
        "                            attendance_file = f\"Attendance/Attendance_{date}.csv\"\n",
        "                            if not os.path.isfile(attendance_file):\n",
        "                                df_attendance = pd.DataFrame(columns=['ID', 'Name', 'Date', 'Time'])\n",
        "                            else:\n",
        "                                df_attendance = pd.read_csv(attendance_file)\n",
        "                            df_attendance = df_attendance.append(attendance_record, ignore_index=True)\n",
        "                            df_attendance.to_csv(attendance_file, index=False)\n",
        "                            st.success(f\"Attendance marked for {name} at {timeStamp}\")\n",
        "                    else:\n",
        "                        cv2.putText(frame, \"Unknown\", (x, y+h+30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "                # Display the frame in Streamlit\n",
        "                stframe.image(frame, channels='BGR')\n",
        "\n",
        "                # To stop the loop, press 'q' in the Streamlit interface (Not directly possible, but you can limit the duration)\n",
        "                # For demonstration, let's capture for a fixed number of frames or duration\n",
        "                # Here, we'll break the loop after 100 frames\n",
        "                if len(attendance) >= 100:\n",
        "                    break\n",
        "\n",
        "            cap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "            st.success(\"Attendance tracking completed.\")\n",
        "\n",
        "elif choice == \"About\":\n",
        "    st.subheader(\"About\")\n",
        "    st.text(\"FacePulse AI is a facial recognition-based attendance monitoring system.\")\n",
        "    st.text(\"Developed using Streamlit, OpenCV, and Python.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwJBC20-Mdyb"
      },
      "outputs": [],
      "source": [
        "!ngrok http 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_TOUfoyNH8X",
        "outputId": "3b71165c-5ad1-435d-8cab-bd0447d032f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streamlit app is running at: NgrokTunnel: \"https://8a25-34-29-189-148.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "# Open a tunnel to the Streamlit port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jazV4bHtNTt4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "get_ipython().system_raw('streamlit run app.py &')\n",
        "\n",
        "# Optional: Wait for the app to initialize\n",
        "time.sleep(5)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
